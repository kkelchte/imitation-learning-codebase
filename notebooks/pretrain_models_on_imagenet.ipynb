{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from src.ai.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rodatadir = \"/esat/visicsrodata/datasets/ilsvrc2012\"\n",
    "rodatadir = \"/esat/opal/kkelchte/experimental_data/datasets/dummy_ilsvrc\"\n",
    "\n",
    "traindir = os.path.join(rodatadir, 'ILSVRC2012_img_train')\n",
    "valdir = os.path.join(rodatadir, 'ILSVRC2012_img_train')\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=4, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 0/27]\tTime  1.673 ( 1.673)\tData  0.280 ( 0.280)\tLoss 7.1666e+00 (7.1666e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Epoch: [0][10/27]\tTime  1.253 ( 1.295)\tData  0.000 ( 0.026)\tLoss 1.2957e+00 (1.9424e+00)\tAcc@1  40.00 ( 50.91)\tAcc@5 100.00 ( 86.36)\n",
      "Epoch: [0][20/27]\tTime  1.201 ( 1.271)\tData  0.000 ( 0.013)\tLoss 2.9627e+00 (1.5408e+00)\tAcc@1  50.00 ( 56.67)\tAcc@5 100.00 ( 92.86)\n",
      "Test: [ 0/27]\tTime  0.585 ( 0.585)\tLoss 1.1426e+02 (1.1426e+02)\tAcc@1   0.00 (  0.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.169 ( 0.211)\tLoss 8.9222e+01 (1.1428e+02)\tAcc@1   0.00 (  0.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.148 ( 0.187)\tLoss 0.0000e+00 (7.0913e+01)\tAcc@1 100.00 ( 38.57)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 52.222 Acc@5 100.000\n",
      "Epoch: [1][ 0/27]\tTime  1.738 ( 1.738)\tData  0.266 ( 0.266)\tLoss 1.7138e+00 (1.7138e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [1][10/27]\tTime  1.266 ( 1.295)\tData  0.000 ( 0.024)\tLoss 7.7238e-01 (6.1941e-01)\tAcc@1  80.00 ( 77.27)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [1][20/27]\tTime  1.196 ( 1.268)\tData  0.000 ( 0.013)\tLoss 3.6605e-01 (7.4926e-01)\tAcc@1  90.00 ( 70.95)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 0/27]\tTime  0.556 ( 0.556)\tLoss 1.2979e+00 (1.2979e+00)\tAcc@1  10.00 ( 10.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.159 ( 0.205)\tLoss 1.8358e+00 (1.7522e+00)\tAcc@1  10.00 ( 26.36)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.109 ( 0.178)\tLoss 9.7496e-02 (1.1505e+00)\tAcc@1 100.00 ( 55.71)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 65.185 Acc@5 100.000\n",
      "Epoch: [2][ 0/27]\tTime  1.712 ( 1.712)\tData  0.253 ( 0.253)\tLoss 5.2923e-01 (5.2923e-01)\tAcc@1  70.00 ( 70.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [2][10/27]\tTime  1.255 ( 1.291)\tData  0.000 ( 0.023)\tLoss 5.8618e-01 (6.9310e-01)\tAcc@1  60.00 ( 74.55)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [2][20/27]\tTime  1.191 ( 1.261)\tData  0.000 ( 0.012)\tLoss 9.7167e-01 (5.9569e-01)\tAcc@1  80.00 ( 75.24)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 0/27]\tTime  0.545 ( 0.545)\tLoss 6.4201e-02 (6.4201e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.144 ( 0.192)\tLoss 5.1488e-02 (1.0457e-01)\tAcc@1 100.00 ( 99.09)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.115 ( 0.173)\tLoss 5.7108e-01 (2.1950e-01)\tAcc@1  60.00 ( 90.95)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 89.259 Acc@5 100.000\n",
      "Epoch: [3][ 0/27]\tTime  1.726 ( 1.726)\tData  0.280 ( 0.280)\tLoss 1.5779e-01 (1.5779e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [3][10/27]\tTime  1.264 ( 1.292)\tData  0.000 ( 0.026)\tLoss 4.5029e-01 (4.6645e-01)\tAcc@1  70.00 ( 77.27)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [3][20/27]\tTime  1.251 ( 1.267)\tData  0.000 ( 0.013)\tLoss 2.6783e-01 (4.2933e-01)\tAcc@1  90.00 ( 77.14)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 0/27]\tTime  0.542 ( 0.542)\tLoss 5.1287e-03 (5.1287e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.157 ( 0.192)\tLoss 1.3494e-02 (2.4356e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.112 ( 0.171)\tLoss 8.5442e-01 (3.3731e-01)\tAcc@1  70.00 ( 88.57)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 83.704 Acc@5 100.000\n",
      "Epoch: [4][ 0/27]\tTime  1.706 ( 1.706)\tData  0.277 ( 0.277)\tLoss 3.5006e-01 (3.5006e-01)\tAcc@1  90.00 ( 90.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [4][10/27]\tTime  1.240 ( 1.275)\tData  0.000 ( 0.025)\tLoss 7.4035e+00 (1.1599e+00)\tAcc@1  30.00 ( 76.36)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [4][20/27]\tTime  1.226 ( 1.254)\tData  0.000 ( 0.013)\tLoss 4.0436e-01 (1.0242e+00)\tAcc@1  80.00 ( 76.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 0/27]\tTime  0.575 ( 0.575)\tLoss 2.0199e-01 (2.0199e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.153 ( 0.197)\tLoss 2.1429e-01 (3.1350e-01)\tAcc@1 100.00 ( 87.27)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.151 ( 0.177)\tLoss 1.8045e-01 (2.9271e-01)\tAcc@1  90.00 ( 88.10)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.148 Acc@5 100.000\n",
      "Epoch: [5][ 0/27]\tTime  1.757 ( 1.757)\tData  0.289 ( 0.289)\tLoss 3.8003e-01 (3.8003e-01)\tAcc@1  80.00 ( 80.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [5][10/27]\tTime  1.253 ( 1.307)\tData  0.000 ( 0.026)\tLoss 1.7182e-01 (3.6178e-01)\tAcc@1  90.00 ( 84.55)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [5][20/27]\tTime  1.203 ( 1.274)\tData  0.000 ( 0.014)\tLoss 8.7142e-02 (3.5471e-01)\tAcc@1 100.00 ( 85.24)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 0/27]\tTime  0.551 ( 0.551)\tLoss 3.7152e-01 (3.7152e-01)\tAcc@1  90.00 ( 90.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.169 ( 0.198)\tLoss 6.8056e-01 (4.8671e-01)\tAcc@1  70.00 ( 80.91)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.113 ( 0.175)\tLoss 3.1480e-01 (3.7945e-01)\tAcc@1  80.00 ( 83.81)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.926 Acc@5 100.000\n",
      "Epoch: [6][ 0/27]\tTime  1.939 ( 1.939)\tData  0.499 ( 0.499)\tLoss 4.9256e-01 (4.9256e-01)\tAcc@1  90.00 ( 90.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [6][10/27]\tTime  1.248 ( 1.329)\tData  0.000 ( 0.045)\tLoss 1.0535e+00 (4.6384e-01)\tAcc@1  40.00 ( 80.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [6][20/27]\tTime  1.203 ( 1.287)\tData  0.000 ( 0.024)\tLoss 5.3797e-01 (4.1355e-01)\tAcc@1  70.00 ( 81.43)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 0/27]\tTime  0.544 ( 0.544)\tLoss 1.0353e-01 (1.0353e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.175 ( 0.208)\tLoss 8.5357e-02 (1.1902e-01)\tAcc@1 100.00 ( 98.18)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.154 ( 0.184)\tLoss 4.1605e-01 (1.7868e-01)\tAcc@1  80.00 ( 92.86)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 90.000 Acc@5 100.000\n",
      "Epoch: [7][ 0/27]\tTime  1.705 ( 1.705)\tData  0.270 ( 0.270)\tLoss 2.3873e-01 (2.3873e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [7][10/27]\tTime  1.242 ( 1.301)\tData  0.000 ( 0.025)\tLoss 2.5888e-01 (3.2243e-01)\tAcc@1  90.00 ( 89.09)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [7][20/27]\tTime  1.258 ( 1.273)\tData  0.000 ( 0.013)\tLoss 1.4530e-01 (3.8391e-01)\tAcc@1 100.00 ( 88.57)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 0/27]\tTime  0.562 ( 0.562)\tLoss 4.8739e-02 (4.8739e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.152 ( 0.194)\tLoss 7.7401e-02 (9.0943e-02)\tAcc@1 100.00 ( 98.18)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.108 ( 0.171)\tLoss 4.9865e-01 (2.0756e-01)\tAcc@1  60.00 ( 89.05)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.519 Acc@5 100.000\n",
      "Epoch: [8][ 0/27]\tTime  1.745 ( 1.745)\tData  0.263 ( 0.263)\tLoss 6.2247e-01 (6.2247e-01)\tAcc@1  80.00 ( 80.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [8][10/27]\tTime  1.206 ( 1.288)\tData  0.000 ( 0.024)\tLoss 5.8732e-01 (4.0053e-01)\tAcc@1  60.00 ( 80.91)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [8][20/27]\tTime  1.265 ( 1.276)\tData  0.000 ( 0.013)\tLoss 5.8028e-01 (4.1181e-01)\tAcc@1  70.00 ( 80.48)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 0/27]\tTime  0.541 ( 0.541)\tLoss 1.8793e-01 (1.8793e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.181 ( 0.207)\tLoss 1.5980e-01 (2.2748e-01)\tAcc@1 100.00 ( 96.36)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.112 ( 0.177)\tLoss 2.3235e-01 (2.0818e-01)\tAcc@1  90.00 ( 93.81)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 94.074 Acc@5 100.000\n",
      "Epoch: [9][ 0/27]\tTime  1.754 ( 1.754)\tData  0.277 ( 0.277)\tLoss 1.3335e-01 (1.3335e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [9][10/27]\tTime  1.223 ( 1.297)\tData  0.000 ( 0.025)\tLoss 8.4254e-02 (2.7164e-01)\tAcc@1 100.00 ( 82.73)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [9][20/27]\tTime  1.218 ( 1.274)\tData  0.000 ( 0.013)\tLoss 1.6060e-01 (2.8159e-01)\tAcc@1  90.00 ( 86.67)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 0/27]\tTime  0.573 ( 0.573)\tLoss 1.3863e-01 (1.3863e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [10/27]\tTime  0.146 ( 0.194)\tLoss 1.8718e-01 (1.6413e-01)\tAcc@1 100.00 ( 97.27)\tAcc@5 100.00 (100.00)\n",
      "Test: [20/27]\tTime  0.133 ( 0.178)\tLoss 3.3768e-01 (1.8818e-01)\tAcc@1  80.00 ( 93.33)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 93.333 Acc@5 100.000\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "model = models.__dict__['resnet18']()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        acc1 = validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = 0.01 * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
