architecture_config:
  architecture: fleeing_actor_critic
  device: cpu
  log_std: 0.01
  random_seed: 5346
  initialisation_type: orthogonal
data_saver_config:
  clear_buffer_before_episode: true
  store_on_ram_only: true
environment_config:
  normalize_observations: false
  normalize_rewards: true
  factory_key: GYM
  gym_config:
    random_seed: 5346
    render: false
    world_name: tracking-v0
  max_number_of_steps: 200  # let number of steps depend on environment
number_of_episodes: 10  # stop when there are enough samples in buffer to fill batch
number_of_epochs: 1000
output_path: test_tracking
save_checkpoint_every_n: 100
tb_render_every_n_epochs: 10
tensorboard: true
trainer_config:
  scheduler_config:
    number_of_epochs: 1000
  criterion: MSELoss
  critic_learning_rate: 0.0001
  actor_learning_rate: 0.00001
  gradient_clip_norm: -1
  optimizer: RMSprop
  data_loader_config:
    batch_size: 50
    random_seed: 5346
  device: cpu
  discount: 0.99
  factory_key: PPO
  gae_lambda: 0.95
  phi_key: gae
  entropy_coefficient: 0.01
  max_actor_training_iterations: 50
  max_critic_training_iterations: 10
  ppo_epsilon: 0.2
  kl_target: 0.01
  use_kl_stop: true